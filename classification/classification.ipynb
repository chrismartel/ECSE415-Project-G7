{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxFxSRjr2BJugc30HZwvGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrismartel/ECSE415-Project-G7/blob/main/classification/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Download Vehicle Dataset"
      ],
      "metadata": {
        "id": "QnE4ItFOypEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O output https://mcgill-my.sharepoint.com/:u:/g/personal/raghav_mehta_mail_mcgill_ca/EVEvhY9_jyVEk2uSZ8wZhFYBQ58C57I7ZB55jBocKwB5Jg?download=1\n",
        "!mv output dataset.zip\n",
        "!unzip dataset.zip\n",
        "!rm dataset.zip"
      ],
      "metadata": {
        "id": "evGmtRtpx1SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import cv2 as cv\n",
        "\n",
        "def parse(filepath):\n",
        "  '''\n",
        "      Parse gt.txt with format\n",
        "        <frame>, <id>, <type>, <truncated>, <occluded>, <alpha>, <bb_left>, <bb_top>, <bb_right>, <bb_bottom>, <3D_H>, <3D_W>, <3D_L>, <x>, <y>, <z>, <ry>\n",
        "      Return dict as:\n",
        "        <type> = \"Car\", \"Van\", \"Truck\", \"Pedastrian\", \"Person_sitting\", \"Cyclist\", \"Tram\", \"Misc\", \"DontCare\"\n",
        "        key: frame\n",
        "        value: list - <id>, <bb_left>, <bb_top>, <bb_right>, <bb_bottom>, <is_vehicle>\n",
        "      Feel free to edit your structure as needed!\n",
        "  '''\n",
        "\n",
        "  used_type = [\"Car\", \"Van\", \"Truck\", \"Tram\"]\n",
        "\n",
        "  lines = open(filepath, \"r\").readlines()                                 \n",
        "  bbox = {}\n",
        "\n",
        "       #  <frame>, <id>, <truncated>, <occluded>, <alpha>, <bb_left>, <bb_top>, <bb_right>, <bb_bottom>, <3D_H>, <3D_W>, <3D_L>, <x>,   <y>,   <z>,   <ry>\n",
        "  mask = [False,   True,  False,       False,      False,   True,      True,     True,       True,        False,  False,  False,  False, False, False, False]\n",
        "  \n",
        "  for line in lines:\n",
        "    l = line.strip().split(' ') #convert line to list\n",
        "    typ = l.pop(2)  # get type of bbox \n",
        "    line = np.asarray(l).astype(np.float32) # convert into array \n",
        "    frame, line = int(line[0]), line[mask] # get frame number and mask the line   \n",
        "    if frame not in bbox.keys():\n",
        "      bbox[frame] = []   \n",
        "    if typ in used_type:\n",
        "        bbox[frame].append(line)\n",
        "  return bbox\n",
        "\n",
        "def add_bbox(img, bbox, color=(255, 0, 0), thickness=2):\n",
        "  ''' \n",
        "    annotate an image with bounding boxes:\n",
        "    supports single bbox or list of bboxs\n",
        "  '''\n",
        "\n",
        "  annotated = np.copy(img)\n",
        "  if bbox: \n",
        "    if isinstance(bbox[0], np.ndarray) or isinstance(bbox[0], list):\n",
        "        for (_,x1,y1,x2,y2) in bbox:\n",
        "            cv.rectangle(annotated, (x1, y1), (x2, y2), color , thickness)\n",
        "    else:\n",
        "        _,x1,y1,x2,y2 = bbox\n",
        "        cv.rectangle(annotated, (x1, y1), (x2, y2), color , thickness)\n",
        "  \n",
        "  return annotated"
      ],
      "metadata": {
        "id": "mz9hXuewy1N7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "r1: tuple (x1,y1,x2,y2) coordinates of rectangle 1\n",
        "r2: tuple (x1,y1,x2,y2) coordinates of rectangle 2\n",
        "\"\"\"\n",
        "def intersection(r1, r2):\n",
        "  if r1[0] >= r2[2] or r1[2] <= r2[0] or r1[1] >= r2[3] or r1[3] <= r2[1]:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "SRowSE1vJEdz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Dataset**\n",
        "\n",
        "https://iq.opengenus.org/object-detection-with-histogram-of-oriented-gradients-hog/"
      ],
      "metadata": {
        "id": "77efUfVlxzjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Positive Dataset\n",
        "\n",
        "Use provided bounding boxes from train dataset\n",
        "\n",
        "###Negative Dataset\n",
        "\n",
        "Use different objects from random patches in train dataset"
      ],
      "metadata": {
        "id": "4nyPjabFx3_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.cbook import maxdict\n",
        "import os\n",
        "import cv2 as cv\n",
        "from random import randint\n",
        "\n",
        "positive_dataset = list()\n",
        "\n",
        "negative_dataset = list()\n",
        "\n",
        "number_of_negative_samples_per_frame = 10\n",
        "\n",
        "minimum_bbox_h, maximum_bbox_h = 40, 150\n",
        "minimum_bbox_w, maximum_bbox_w = 50, 200\n",
        "\n",
        "max_diff_width_height = 20\n",
        "\n",
        "for image_sequence in range(4):\n",
        "  bboxes = parse('dataset/000{image_sequence}.txt'.format(image_sequence=image_sequence))\n",
        "  for frame_id, frame_bboxes in bboxes.items():\n",
        "\n",
        "    img = cv.imread('dataset/000{image_sequence}/{frame_id:06d}.png'.format(image_sequence=image_sequence, frame_id=frame_id))\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    for sample in range(number_of_negative_samples_per_frame):\n",
        "\n",
        "        while(True):\n",
        "          random_y1 = randint(0,img.shape[0])\n",
        "          random_y2 = randint(random_y1,img.shape[0])\n",
        "\n",
        "          random_x1 = randint(0,img.shape[1])\n",
        "          random_x2 = randint(random_x1,img.shape[1])\n",
        "\n",
        "          # validate dimensions\n",
        "          if random_y2 - random_y1 < minimum_bbox_h or random_y2 - random_y1 > maximum_bbox_h:\n",
        "            continue\n",
        "          if random_x2 - random_x1 < minimum_bbox_h or random_x2 - random_x1 > maximum_bbox_w:\n",
        "            continue\n",
        "\n",
        "          if abs((random_x2 - random_x1) - (random_y2 - random_y1)) > max_diff_width_height:\n",
        "            continue\n",
        "\n",
        "          random_bbox = (random_x1, random_y1, random_x2, random_y2)\n",
        "\n",
        "          # validate no-intersection with vehicles\n",
        "          valid = True\n",
        "          for (id, x1,y1,x2,y2) in frame_bboxes:\n",
        "            if intersection((x1,y1,x2,y2), random_bbox):\n",
        "              valid = False\n",
        "              break\n",
        "\n",
        "          if valid:\n",
        "            break\n",
        "\n",
        "        # extract patch\n",
        "        random_bbox_img = img[random_y1:random_y2,random_x1:random_x2]\n",
        "        negative_dataset.append(random_bbox_img)\n",
        "\n",
        "    for bbox in frame_bboxes:\n",
        "      id, x1, y1, x2, y2 = bbox.astype('int32')\n",
        "      \n",
        "      bbox_img = img[y1:y2,x1:x2]\n",
        "      positive_dataset.append(bbox_img)"
      ],
      "metadata": {
        "id": "L_ZIB2HQz0_J"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c3fiVmsUTTV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7QA0drCaSp67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}